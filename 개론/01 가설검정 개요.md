# 가설검정 개요

통계적 추측의 하나로서, 모집단 실제의 값이 얼마가 된다는 주장과 관련해, 표본의 정보를 사용해서 가설의 합당성 여부를 판정하는 과정이다.

주로 변수간의 평균에 차이가 있는지를 확인한다.

두 그룹 간의 평균 차이를 비교하는 경우 **가설검정(T-Test)** 을 수행하고, 세 개 이상의 그룹 간의 평균 차이를 비교하는 경우 **분산분석(F-Test)** 를 수행한다.

한편 범주형 변수간의 관련성이나 독립성을 검정하기 위한 통계적 방법으로는 **카이제곱 검정(Chi-square Test)** 이 있다.

## #01. 추정

표본으로부터 미지의 모수를 추측하는 것

### [1] 점추정

- ‘모수가 특정한 값일 것’ 이라고 추정하는 것
- 표본의 평균, 중위수, 최빈값 등을 사용

### [2] 구간추정(=가설검정)

- 점추정의 정확성을 보완하기 위해 확률로 표현된 믿음의 정도 하에서 모수가 특정한 구간에 있을 것이라고 선언하는 것
- 항상 추정량의 분포에 대한 전제가 주어져야 하고 구해진 구간 안에 모수가 있을 가능성의 크기(신뢰수준)가 주어져야 한다.
- T검정과 F검정등의 방법이 있다.

#### (1) 가설검정의 절차

```plain
💡 가설 설정 ▶ 유의수준 설정 ▶ 검정통계량 산출 ▶ 기각/채택 판단
```

## #02. 가설검정의 주요 용어

### (1) 표본

관찰이나 조사 대상

### (2) 설명변수($x$)

- `○○이 ■■에 주는 영향`에서 `○○`에 해당
- `독립변수`라고 부르기도 함

### (3) 반응변수($y$)

- `○○이 ■■에 주는 영향`에서 `■■`에 해당
- `종속변수`라고 부르기도 함

### (4) 귀무가설(영가설, $H_0$)

- 일반적으로 맞다고 가정하는 가설
- 모집단 평균(`μ`)이 가설 평균(`μ0`)과 **차이가 없다, 영향력이 없다, 연관성이 없다, 효과가 없다. (부정)**

```
💡 설명변수(`x`)는 반응변수(`y`)에 영향을 주지 않는다.
```

#### 예시

```plain
💡 새로 개발한 백신은 감기 예방에 영향을 주지 않는다.
💡 새로 개발한 백신은 감기 예방과 연관성이 없다.
💡 새로 개발한 백신은 감기 예방에 효과가 없다.
```

### (5) 대립가설($H_1$)

- 분석가가 증명하고자 하는 가설
- 귀무 가설에 대한 부정
- 모집단 평균(`μ`)이 가설 평균(`μ0`)과 **차이가 있다, 영향력이 있다, 연관성이 있다, 효과가 있다. (긍정)**.

```plain
💡 설명변수(`x`)는 반응변수(`y`)에 영향을 준다.
```

#### 예시

```plain
💡 새로 개발한 백신은 감기 예방에 영향을 준다.
💡 새로 개발한 백신은 감기 예방과 연관성이 있다.
💡 새로 개발한 백신은 감기 예방에 효과가 있다.
```

### (6) 검정 통계량 (test statistic)

귀무 가설이 맞거나 틀린 것을 증명하려면 어떤 증거가 있어야 한다. 이 증거에 해당하는 숫자를 검정 통계량(test statistics)라고 한다.

- 관찰된 표본으로부터 구하는 통계량
- 검정 시 가설의 진위를 판단하는 기준

#### 예시

```plain
💡 백신을 접종한 집단 A에 대한 감기 발병률
💡 백신을 접종 하지 않은 집단 B에 대한 감기 발병률
```

### (7) 유의수준 (significance level,  $a$)

> `p-value`

가설이 어느 정해진 수치를 벗어나면 귀무가설이 오류라고 인정할 것인가를 판단하는 기준.

즉, 귀무가설을 기각하게 되는 확률의 크기

일반적으로 `5%`로 본다.

```
💡 감기가 걸린 환자 100명에서 백신을 접종하게 했을 때 예방이 감기에 걸리지 않은 사람이 95% 이상이라면
감기에 걸린 사람은 유의수준 5% 미만이므로 백신이 효과가 있는 것으로 본다.
```

`p-value`는 귀무 가설(null hypothesis)이 맞다는 전제 하에, 표본에서 실제로 관측된 통계치와 '같거나 더 극단적인' 통계치가 관측될 확률이다.

`p-value`는 관찰된 데이터가 귀무가설과 양립하는 정도를 0에서 1 사이의 수치로 표현한 것이다.

`p-value`가 작을수록 그 정도가 약하다고 보며, 특정 값 (대개 0.05나 0.01 등) 보다 작을 경우 귀무가설을 기각하는 것이 관례.

`p-value`가 1인 경우는 귀무가설을 기각할 근거가 없다는 의미

`p-value`가 0이라는 것은 주어진 데이터에서 검정하는 가설이 완전히 거부되어야 한다는 것을 의미

### (8) 신뢰수준

유의수준의 반대.

유의수준이 `0.05`일 때, 신뢰수준은 `0.95`가 된다.

### (9) 기각역 (critical region, $C$)

귀무가설이 옳다는 전제 하에서 구한 검정통계량의 분포에서 확률이 유의수준 $a$인 부분

반대는 채택역(acceptance region)

## #03. 가설검정의 가정

가설검정을 수행하기 위해서는 데이터의 **정규성**, **등분산성**, **독립성**이 확인되어야 한다.

### [1] 데이터 정규성 확인

검정 대상인 두 그룹의 데이터는 정규분포를 따라야 한다.

또한 추론통계(모든 머신러닝 알고리즘)를 수행하기 위해서는 각각의 변수가 정규성을 충족하는지 확인해야 한다.

각 샘플 데이터는 정규분포를 따르는 모집단으로 부터 추출되었는지를 확인하기 위해 정규분포의 모양과 수집된 데이터의 분포모양을 비교하는 것이다.

![img](res/QnQ1_1.png)

정규성을 검정하는 방법으로는 Shapiro Wilk 검정과 Normal Test가 있다.

특히 Normal Test는 왜도와 첨도를 통한 기술 통계량 판단 방법으로 널리 사용되는 방법이다.


#### (1) 정규성 가설

| 구분 | 내용 |
|---|---|
| 귀무가설 ($H_0$) | 정규분포의 모양과 수집된 데이터의 분포모양(표본자료의 분포)은 차이가 없다(같다) |
| 대립가설 ($H_1$) | 정규분포의 모양과 표본자료의 분포 모양은 차이가 있다(다르다) |

정규성은 귀무가설이 채택이 되어야 정규분포의 모양과 비슷하다 혹은 크게 다르지 않다가 된다.

따라서 p(유의확률)값이 `0.05`보다 큰 것이 좋다.

#### (2) 정규성을 판단하는 방법

현실에서 다루는 대부분 데이터는 정규성 검정에 위배되기 때문에 전공 수업과 같이 원론적으로만 접근하는 경우에만 적용되고 실제 데이터에는 적용이 어려운 경우가 많다.

Shapiro Wilk 검정은 매우 엄격하고 이를 충족하기 위해서는 이상치가 없어야 하며 좌우 대칭도 거의 완전해야 하기 때문에 현실에서 이 기준에 맞는 데이터는 없다고 보는 것이 맞다.

그러므로 실제로는 히스토그램을 그려보고, 왜도와 첨도의 통계량으로 판단하는게 현실적이다.

West 등(1995)의 연구에 따르면 정규분포 기준은 $|왜도| < 2$, $|첨도| < 7$이면 정규분포에서 크게 벗어나지 않아 정규성을 충족한다고 볼 수 있다.

| 정규성 진단 방법 | 정규성 충족 기준 |
|---|---|
| 1. 히스토그램을 통한 직관적 판단 | 정규분포모양에서 크게 다르지 않을 경우(자료가 중심에 몰려 있어야 함) |
| 2. 왜도와 첨도를 통한 기술통계량 판단 | 왜도의 절대값이 2보다 작고 첨도의 절대값이 7보다 작은 경우 |
| 3. 정규성에 대한 가설검정 | $p > 0.05$ (귀무가설 충족) |

정규성을 파악해보는 중요한 이유는 평균이 평균으로서 자격이 있는지를 보는 것이다.

왜냐면 대부분의 통계분석은 바로 평균 중심성 간의 차이나 관계를 파악하는 것이기 때문이다.

이를 반영한 검정은 scipy 패키지의 Normal Test가 있다.

#### (3) 정규분포가 아닌 경우

데이터에 대해 로그변환이나 제곱근 변환을 적용하여 정규분포에 가깝게 변환해야 한다.

#### (4) 데이터의 길이가 30 이상인 경우

확률론과 통계학에서 중심 극한 정리는 동일한 확률분포를 가진 독립 확률 변수 $n$개의 평균의 분포는 $n$이 적당히 크다면 정규분포에 가까워진다는 정리이다. 수학자 피에르시몽 라플라스는 1774년에서 1786년 사이의 일련의 논문에서 이러한 정리의 발견과 증명을 시도하였다.(위키미디어)

그러므로 통계학에서는 **일반적으로 데이터의 표본수가 30개 이상이면 정규분포를 따른다고 본다**.

### [2] 데이터의 등분산성 확인

등분산성 가정은 각각의 그룹 또는 조건에서 오차의 분산이 동일하다는 가정으로 주로 분산분석(ANOVA) 및 회귀분석에서 사용된다.

등분산성이 있다면, 통계적 분석 결과가 신뢰성 있고 정확하며 해석이 쉽다.

그러나 등분산성이 깨진다면, 잘못된 결과를 얻을 수 있기 때문에 등분산성을 확인하고 적절한 조치를 취하는 것이 중요하다.

등분산성은 주로 잔차(Residual)의 분포를 통해 확인한다.

분석을 진행하기 전에 등분산성을 검정하고, 등분산성이 깨진 경우에는 적절한 변환을 시도하거나 다른 분석 방법을 사용하는 것이 좋다.

즉, 등분산성 가정을 충족해야 분산분석이 성립된다.

#### (1) 정규분포를 따르는 데이터의 검정 - Bartlett 검정

정규분포를 따르는 데이터의 집단간 분산이 같은지 다른지 여부를 알아볼 때 사용

Bartlett 검정은 두 집단 뿐만 아니라 세 집단 이상에서도 사용할 수 있음

모든 변수가 정규분포를 따른다는 가정 하에서만 사용 가능함

| 가설 | 내용 |
|---|---|
| 귀무가설 ($H_0$) | 집단간 분산이 차이가 없다(같다) |
| 대립가설 ($H_1$) | 집단간 분산이 차이가 있다(다르다) |

Bartlett 검정 외에 정규분포 가정 하에 Filgner-Killeen 검정을 사용할 수도 있으나 Bartlett 검정이 좀 더 일반적이다.

#### (2) 정규분포를 따르지 않는 데이터의 검정 - 레빈 검정(Levene's test)

다른 등분산성 검정 방법과 달리 레빈 검정은 정규성 가정이 필요 없기 때문에 비모수적인 방법으로도 적용할 수 있다.

| 가설 | 내용 |
|---|---|
| 귀무가설 ($H_0$) | 집단간 분산이 차이가 없다(같다) |
| 대립가설 ($H_1$) | 집단간 분산이 차아가 있다(다르다) |

레빈 검정 외에 Brown-Forsythe 검정을 사용할 수도 있으나 레빈 검정이 좀 더 일반적이다.

### [3] 데이터의 독립성 확인

시계열 데이터가 아닌 경우, 데이터의 독립성은 주로 관찰치 간에 상관관계가 없는지 확인하는 것으로 파악된다.

일반적으로 데이터 수집 시에 독립성이 확보되므로 추가적인 검정이 필요하지 않을 수 있다.

## #04. T검정(T-Test)

모집단의 분산이나 표준편차를 알지 못할 때, 표본으로부터 추정된 분산이나 표준편차를 이용하여 두 모집단의 평균에 통계적으로 유의한 차이가 있는지 알아볼 때 사용하는 통계 분석 기법

모집단에 대한 어떤 가설을 설정한 뒤에 표본관찰을 통해 그 가설의 채택여부를 결정한다.

```
💡 ex) 새로 개발한 백신이 감기를 예방하는데 효과가 있는지 여부를 결정하는 분석
```

귀무가설이 옳다는 전제하에 검정통계량 값을 구한 후에 이 값이 나타날 가능성의 크기에 의해 귀무가설의 채택여부를 결정한다.

통계적인 유의성을 검정하는 것으로, 유의성 검정(Significance Test)이라고도 한다.

### [1] T-검정의 종류

| 종류 | 설명 |
|--|--|
| 단일 표본 t-검정<br/>`One-Sample T-test` | 하나의 모집단 평균이 이전보다 커졌는지/작아졌는지/달라졌는지를 통계적으로 알아보기 위해 사용 |
| 독립 표본 t-검정<br/>`Independent two sample T-test` | 서로 다른 두개의 그룹 간 평균의 차이가 유의미한지 여부를 판단 |
| 대응 표본 t-검정<br/>`Paired T-test` | 표본의 각 사례마다 대응하는 2개의 관측치를 통해 판단<br/>쉽게 풀이하면 한 집단에 어떤 작용이 가해졌을 때에 대한 before, after를 비교 |


## #05. F검정 (분산분석, ANOVA)

세 개 이상의 집단 간 평균의 차이를 검증하기 위해 사용된다.

두 집단의 평균을 비교할 때는 t 검정을 쓰고, 3개 이상의 집단의 평균을 비교할 때는 분산 분석을 수행한다고 볼 수 있다.

두 집단의 평균을 비교하기 위해 분산분석을 사용할 경우 독립표본 T검정과 동일하다.

분산분석 주요 목표는 두 가지 이상의 집단 간의 평균이 서로 같은지를 판단하는 것이다. 그래서 귀무가설과 대립가설을 세울 때는 평균이 서로 "같은지", "다른지"만 나타내는데, T검정과 달리 방향은 중요하지 않기 때문에 가설검정처럼 "크다"와 "작다"는 파악하지 않는다.

파이썬에서는 `scipy.stats` 패키지를 통해 분산분석을 수행하기 위한 요건을 검사하고 `statsmodels` 패키지를 활용하여 분산분석을 수행한다.


### [1] F검정의 종류

| 종류 | 이름 | 설명 |
|---|---|---|
| 일원분산분석 | One-way ANOVA | 하나의 독립변수에 대한 종속변수의 평균 차이를 분석하는 방법.<br/>(ex: 세 가지 다른 교육 방법에 따른 학생들의 성적 차이) |
| 이원분산분석 | Two-way ANOVA | 두 개의 독립변수에 대한 종속변수의 평균 차이를 분석하는 방법으로 두 가지 요인이 결과 변수에 미치는 영향을 동시에 조사할 수 있다.<br/>(ex: 교육 방법과 성별에 따른 학생들의 성적 차이를 분석) |

### [2] F검정의 가설

| 가설 | 설명 | 식 |
|--|--|--|
| 귀무가설 ($H_0$) | 모든 집단의 평균이 같다 | $H_0 : \sigma_1 = \sigma_2$
| 대립가설 ($H_1$) | 어떤 집단의 평균이 다르다 | $H_0 : \sigma_1 \neq \sigma_2$

`p < 유의수준`이면 귀무가설을 기각하고, 대립가설을 채택한다.

대립가설의 요점은 "어떤 집단의 평균이 다르다"이다.

집단이 A, B, C가 있으면 A와 B가 다른지 B와 C가 다른지는 분산 분석으로 알 수 없다.

> A와 B가 다른지 B와 C가 다른지는 사후 검정으로 확인해야 한다.

### #04. 가설검정의 오류

| 구분 | 설명 |
|---|---|
| 제1종 오류 | 귀무가설이 사실인데도 불구하고 사실이 아니라고 판정하여 대립가설을 채택(귀무가설을 기각)하는 경우 |
| 제2종 오류 | 귀무가설이 거짓인데도 불구하고 사실이라고 판정하여 대립가설을 기각(귀무가설을 채택)하는 경우 |

요류를 범하지 않기 위해서는 가설검정을 수행하기 전 각 변수가 가설검정의 가정을 충족하는지 확인해야 한다.


## 참고문헌

- West, S. G., Finch, J. F., & Curran, P. J. (1995). Structural equation models with nonnormal variables: Problems and remedies. In R. H. Hoyle (Ed.), Structural equation modeling: Concepts, issues, and applications (p. 56–75). Sage Publications, Inc.
- egoism2002, "정규성 검정이 꼭 충족되어야 하나요?", 사회와 인간을 보는 눈, 2021-05-12, https://blog.naver.com/egoism2002/222348179768
- 위키백과, 중심극한정리, https://ko.wikipedia.org/wiki/%EC%A4%91%EC%8B%AC_%EA%B7%B9%ED%95%9C_%EC%A0%95%EB%A6%AC


## 가설검정과 관련된 Kaggle 예제

https://www.kaggle.com/code/ipravin/hypothesis-testing-using-t-test

https://www.kaggle.com/code/rushinaik/t-tests-with-example/input

https://www.kaggle.com/code/kappernielsen/independent-t-test-example/notebook

https://www.kaggle.com/code/brekhnaa/analysis-of-variance-anova/notebook

https://www.kaggle.com/code/ekretsch/student-exam-performance-visualization-and-anova/notebook

https://www.kaggle.com/code/evitaginiyatullina/one-way-anova-comparison/notebook